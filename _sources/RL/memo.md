# Terminologies

## Policies

ポリシーはアクションを決めるルール

決定的なポリシー
: $a_t = \mu(S_t)$ または $a_t = \mu_\theta(S_t)$

確率的なポリシー
: $a_t \sim \pi(S_t)$ または $a_t \sim \pi_\theta(S_t)$

※$\theta$はポリシーのパラメータ(モデルの重み、バイアスなど)を表す

### Deterministic Policies

### Diagonal Gaussian Policies

多変量ガウス分布（または多変量正規分布）は、平均ベクトル、 、共分散行列、によって記述されます。対角ガウス分布は，共分散行列が対角上のエントリのみを持つ特殊なケースです．その結果、ベクトルで表すことができます。

対角ガウス分布ポリシーは，常に観測値から平均行動に対応するニューラルネットを持つ，．共分散行列は通常2つの異なる方法で表現される．

第一の方法。対数標準偏差のベクトルは1つで、これは状態の関数ではありません：これらは独立したパラメータです。(You Should Know: VPG, TRPO, PPOの実装はこの方法です)。

2つ目の方法。状態から対数標準偏差にマッピングするニューラルネットがある、.これはオプションで平均ネットワークといくつかの層を共有することができる。

どちらの場合も、標準偏差を直接出力するのではなく、対数標準偏差を出力していることに注意。これは、標準偏差は非負でなければならないのに対して、対数標準偏差はどのような値をとってもよいからです。このような制約がなければ、パラメータの学習が容易になります。標準偏差は対数標準偏差を指数化することですぐに求めることができるので、この方法で表現しても何も損なわれることはありません。

サンプリング:平均行動と標準偏差，および球形ガウス（）からのノイズのベクトルが与えられると，行動サンプルは次のように計算される．



ここで，2つのベクトルの要素毎の積を表します．標準的なフレームワークには、 torch.normal や tf.random_normal のようなノイズベクトルを生成する方法が組み込まれています。また，torch.distributes.Normalやtf.distributes.Normalなどの分布オブジェクトを作り，それを用いてサンプルを生成することもできます．(後者の利点は、これらのオブジェクトが対数尤度を計算してくれることです）。


対数尤度: 平均$\mu = \mu_\theta(s)$と標準偏差$\sigma = \sigma_\theta(s)$を持つ対角ガウシアンに対する k次元の行動 a、の対数尤度は次式で与えられる。

